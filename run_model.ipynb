{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a94ce028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsl/anaconda3/envs/chatglm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'transformers' from '/home/dsl/anaconda3/envs/chatglm/lib/python3.11/site-packages/transformers/__init__.py'> \n",
      " /home/dsl/anaconda3/envs/chatglm/lib/python3.11/site-packages/transformers/__init__.py\n",
      "<module 'tokenizers' from '/home/dsl/anaconda3/envs/chatglm/lib/python3.11/site-packages/tokenizers/__init__.py'> \n",
      " /home/dsl/anaconda3/envs/chatglm/lib/python3.11/site-packages/tokenizers/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import transformers, tokenizers, inspect, os\n",
    "print(transformers, \"\\n\", transformers.__file__)\n",
    "print(tokenizers,   \"\\n\", tokenizers.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c600e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsl/anaconda3/envs/chatglm/lib/python3.11/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/dsl/anaconda3/envs/chatglm/lib/python3.11/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/dsl/anaconda3/envs/chatglm/lib/python3.11/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /home/dsl/anaconda3/envs/chatglm/lib/python3.11/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/home/dsl/anaconda3/envs/chatglm/lib/python3.11/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/dsl/anaconda3/envs/chatglm/lib/python3.11/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
      "  warnings.warn(\n",
      "/home/dsl/anaconda3/envs/chatglm/lib/python3.11/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/dsl/anaconda3/envs/chatglm/lib/python3.11/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 모듈 임포트 완료 및 경로 설정 완료.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm.auto import tqdm\n",
    "import sqlite3\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "# 프로젝트 루트 디렉토리를 Python 경로에 추가합니다.\n",
    "# 이렇게 해야 dataset, models 등 서브 디렉토리의 모듈을 직접 임포트할 수 있습니다.\n",
    "# 현재 Jupyter Notebook이 MANAGER 디렉토리 내에서 실행된다고 가정합니다.\n",
    "project_root = Path(os.getcwd())\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# 커스텀 모듈 임포트\n",
    "from dataset.data import VideoPersonDataset\n",
    "from models.manager_graphtokens import GraphTokenManager\n",
    "from experiments import init_experiment_db, insert_new_experiment, update_experiment_metrics, insert_sample_predictions\n",
    "# train.py, validate.py, eval.py의 핵심 함수를 직접 임포트합니다.\n",
    "# argparse 없이 함수 인자로 직접 값을 전달할 수 있게 됩니다.\n",
    "from train import seed_all, get_dataloaders, evaluate as train_evaluate # train.py의 evaluate는 이름 충돌 피하기 위해 train_evaluate로 변경\n",
    "from validate import run_eval as validate_run_eval, load_ckpt as validate_load_ckpt, get_loader as validate_get_loader\n",
    "from eval import run_test as eval_run_test, load_ckpt as eval_load_ckpt # eval.py의 load_ckpt도 이름 충돌 피하기 위해 변경\n",
    "\n",
    "print(\"모든 모듈 임포트 완료 및 경로 설정 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b52ad59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실험 데이터베이스 'experiment_results.db' 초기화 및 연결 완료.\n",
      "새로운 실험이 ID: 1로 시작되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 실험 설정 (하이퍼파라미터 및 경로)\n",
    "class ExperimentArgs:\n",
    "    def __init__(self):\n",
    "        self.db = \"data/speech_segments.db\" # 데이터베이스 경로\n",
    "        self.cache = \"cache/\" # 캐시 디렉토리\n",
    "        self.frames = \"data/frames/\" # 비디오 프레임 경로\n",
    "        self.wav = \"data/wav/\" # 오디오 파일 경로\n",
    "        self.ckpt_dir = \"checkpoints/\" # 체크포인트 저장 디렉토리\n",
    "        self.epochs = 5 # 훈련 에포크 수\n",
    "        self.lr = 2e-4 # 학습률\n",
    "        self.seed = 42 # 랜덤 시드\n",
    "        self.max_samples = 100 # 디버깅용 샘플 제한 (전체 데이터 사용 시 None)\n",
    "        self.output_csv = \"results_test.csv\" # eval.py에서 개별 예측 저장할 CSV\n",
    "        self.output_json = \"metrics_test.json\" # eval.py에서 최종 메트릭 저장할 JSON\n",
    "\n",
    "args = ExperimentArgs() # 인자 객체 생성\n",
    "\n",
    "# 체크포인트 디렉토리 생성\n",
    "Path(args.ckpt_dir).mkdir(exist_ok=True)\n",
    "\n",
    "# 실험 데이터베이스 초기화 및 연결\n",
    "experiment_db_path = \"experiment_results.db\" # 실험 결과를 저장할 DB 파일명\n",
    "exp_conn = init_experiment_db(db_path=experiment_db_path)\n",
    "print(f\"실험 데이터베이스 '{experiment_db_path}' 초기화 및 연결 완료.\")\n",
    "\n",
    "# 새 실험 레코드 삽입 (초기 정보)\n",
    "experiment_id = insert_new_experiment(exp_conn, args)\n",
    "print(f\"새로운 실험이 ID: {experiment_id}로 시작되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b9ec2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 장치: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:05<00:00,  1.17it/s]\n",
      "/home/dsl/anaconda3/envs/chatglm/lib/python3.11/site-packages/transformers/utils/deprecation.py:172: UserWarning: The following named arguments are not valid for `BeitImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
      "  return func(*args, **kwargs)\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.16it/s]\n",
      "/home/dsl/anaconda3/envs/chatglm/lib/python3.11/site-packages/transformers/utils/deprecation.py:172: UserWarning: The following named arguments are not valid for `BeitImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플: 299, 검증 샘플: 306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:15<00:00,  2.20s/it]\n",
      "/tmp/ipykernel_569065/2459027598.py:23: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 훈련 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Train):   0%|          | 0/299 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.13it/s]\n",
      "Epoch 1 (Train):   0%|          | 0/299 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ChatGLMTokenizer._pad() got an unexpected keyword argument 'padding_side'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m model.train()\n\u001b[32m     31\u001b[39m pbar = tqdm(train_loader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (Train)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mg\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgraph\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlbl\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chatglm/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chatglm/lib/python3.11/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chatglm/lib/python3.11/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chatglm/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chatglm/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MANAGER/dataset/data.py:149\u001b[39m, in \u001b[36mVideoPersonDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    146\u001b[39m gb = GraphBuilder(time_iso=time_iso)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m seg \u001b[38;5;129;01min\u001b[39;00m seg_rows:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     t_emb, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_text_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscript\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     v_emb    = \u001b[38;5;28mself\u001b[39m._video_embed(seg)\n\u001b[32m    151\u001b[39m     a_emb    = \u001b[38;5;28mself\u001b[39m._audio_embed(seg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MANAGER/dataset/data.py:109\u001b[39m, in \u001b[36mVideoPersonDataset._text_embed\u001b[39m\u001b[34m(self, script)\u001b[39m\n\u001b[32m    107\u001b[39m p = \u001b[38;5;28mself\u001b[39m._cache_path(\u001b[33m\"\u001b[39m\u001b[33mtxt::\u001b[39m\u001b[33m\"\u001b[39m + script)\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p.exists(): \u001b[38;5;28;01mreturn\u001b[39;00m torch.load(p)\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m emb, meta = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext_enc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknowledge_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchor_entities\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m torch.save((emb, meta), p)\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m emb, meta\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chatglm/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MANAGER/models/encoder.py:177\u001b[39m, in \u001b[36mTextFeatureExtractor.encode\u001b[39m\u001b[34m(self, utterance_text, **_)\u001b[39m\n\u001b[32m    173\u001b[39m wp = \u001b[38;5;28mself\u001b[39m.wp_tok(utterance_text, return_offsets_mapping=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    174\u001b[39m                  add_special_tokens=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    175\u001b[39m wp_offsets = wp[\u001b[33m\"\u001b[39m\u001b[33moffset_mapping\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m glm_enc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mglm_tok\u001b[49m\u001b[43m(\u001b[49m\u001b[43mutterance_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m    179\u001b[39m glm_ids = glm_enc[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m].tolist()\n\u001b[32m    180\u001b[39m glm_toks = \u001b[38;5;28mself\u001b[39m.glm_tok.convert_ids_to_tokens(glm_ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chatglm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2854\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.__call__\u001b[39m\u001b[34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m   2852\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._in_target_context_manager:\n\u001b[32m   2853\u001b[39m         \u001b[38;5;28mself\u001b[39m._switch_to_input_mode()\n\u001b[32m-> \u001b[39m\u001b[32m2854\u001b[39m     encodings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2856\u001b[39m     \u001b[38;5;28mself\u001b[39m._switch_to_target_mode()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chatglm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2964\u001b[39m, in \u001b[36mPreTrainedTokenizerBase._call_one\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m   2942\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_encode_plus(\n\u001b[32m   2943\u001b[39m         batch_text_or_text_pairs=batch_text_or_text_pairs,\n\u001b[32m   2944\u001b[39m         add_special_tokens=add_special_tokens,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2961\u001b[39m         **kwargs,\n\u001b[32m   2962\u001b[39m     )\n\u001b[32m   2963\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2964\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2965\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2966\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2967\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2978\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2980\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2981\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2982\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2983\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2984\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chatglm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3039\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.encode_plus\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m   3010\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3011\u001b[39m \u001b[33;03mTokenize and prepare for the model a sequence or a pair of sequences.\u001b[39;00m\n\u001b[32m   3012\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3027\u001b[39m \u001b[33;03m        method).\u001b[39;00m\n\u001b[32m   3028\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3030\u001b[39m padding_strategy, truncation_strategy, max_length, kwargs = \u001b[38;5;28mself\u001b[39m._get_padding_truncation_strategies(\n\u001b[32m   3031\u001b[39m     padding=padding,\n\u001b[32m   3032\u001b[39m     truncation=truncation,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3036\u001b[39m     **kwargs,\n\u001b[32m   3037\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3039\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3040\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3042\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3043\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3044\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3045\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3046\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3047\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3049\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3056\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3058\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msplit_special_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3059\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3060\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chatglm/lib/python3.11/site-packages/transformers/tokenization_utils.py:803\u001b[39m, in \u001b[36mPreTrainedTokenizer._encode_plus\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m    800\u001b[39m first_ids = get_input_ids(text)\n\u001b[32m    801\u001b[39m second_ids = get_input_ids(text_pair) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m803\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_for_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfirst_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpair_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43msecond_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    811\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    812\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    813\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    814\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    815\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    816\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chatglm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3539\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.prepare_for_model\u001b[39m\u001b[34m(self, ids, pair_ids, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[39m\n\u001b[32m   3537\u001b[39m \u001b[38;5;66;03m# Padding\u001b[39;00m\n\u001b[32m   3538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m padding_strategy != PaddingStrategy.DO_NOT_PAD \u001b[38;5;129;01mor\u001b[39;00m return_attention_mask:\n\u001b[32m-> \u001b[39m\u001b[32m3539\u001b[39m     encoded_inputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3540\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoded_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3543\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3544\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3545\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3546\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3548\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_length:\n\u001b[32m   3549\u001b[39m     encoded_inputs[\u001b[33m\"\u001b[39m\u001b[33mlength\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlen\u001b[39m(encoded_inputs[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chatglm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3337\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.pad\u001b[39m\u001b[34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, padding_side, return_attention_mask, return_tensors, verbose)\u001b[39m\n\u001b[32m   3335\u001b[39m required_input = encoded_inputs[\u001b[38;5;28mself\u001b[39m.model_input_names[\u001b[32m0\u001b[39m]]\n\u001b[32m   3336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m required_input \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(required_input[\u001b[32m0\u001b[39m], (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m-> \u001b[39m\u001b[32m3337\u001b[39m     encoded_inputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoded_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3339\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3340\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3341\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3344\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m BatchEncoding(encoded_inputs, tensor_type=return_tensors)\n\u001b[32m   3347\u001b[39m batch_size = \u001b[38;5;28mlen\u001b[39m(required_input)\n",
      "\u001b[31mTypeError\u001b[39m: ChatGLMTokenizer._pad() got an unexpected keyword argument 'padding_side'"
     ]
    }
   ],
   "source": [
    "# 훈련 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"훈련 장치: {device}\")\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "seed_all(args.seed)\n",
    "\n",
    "# 데이터 로더 준비\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    db=args.db, cache=args.cache, frames=args.frames, wav=args.wav,\n",
    "    batch=1, max_samples=args.max_samples, seed=args.seed\n",
    ")\n",
    "print(f\"훈련 샘플: {len(train_loader.dataset)}, 검증 샘플: {len(val_loader.dataset)}\")\n",
    "\n",
    "# 모델 로드 및 GPU 이동\n",
    "model = GraphTokenManager().half().to(device)\n",
    "model.train()\n",
    "\n",
    "# 옵티마이저 설정\n",
    "optim = torch.optim.AdamW(\n",
    "    model.parameters(), lr=args.lr, betas=(0.9,0.95), eps=1e-8\n",
    ")\n",
    "scaler = GradScaler()\n",
    "\n",
    "best_f1 = 0.0\n",
    "current_best_ckpt_path = None # 최적 체크포인트 경로 추적\n",
    "\n",
    "print(\"모델 훈련 시작...\")\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch} (Train)\")\n",
    "    for sample in pbar:\n",
    "        g = sample[\"graph\"].to(device)\n",
    "        lbl = sample[\"label\"].float().unsqueeze(0).to(device)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        with autocast():\n",
    "            logit, loss = model(g, sample[\"person\"][0], lbl)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optim)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optim); scaler.update()\n",
    "\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # ── 검증 (Validation) ──\n",
    "    # train.py의 evaluate 함수는 F1만 반환하지만, precision, recall도 필요하므로\n",
    "    # validate.py의 run_eval을 사용하거나 train_evaluate를 수정해야 합니다.\n",
    "    # 여기서는 validate.py의 run_eval을 사용하겠습니다.\n",
    "    val_metrics = validate_run_eval(val_loader, model, device) # run_eval은 dict 반환\n",
    "\n",
    "    print(f\"Epoch {epoch} Val Metrics: {json.dumps(val_metrics, indent=2)}\")\n",
    "\n",
    "    # DB에 검증 성능 업데이트\n",
    "    update_experiment_metrics(exp_conn, experiment_id, \"val\", val_metrics)\n",
    "    print(f\"실험 {experiment_id}의 검증 메트릭이 DB에 업데이트되었습니다.\")\n",
    "\n",
    "    # 최적 모델 저장\n",
    "    if val_metrics['f1'] > best_f1:\n",
    "        best_f1 = val_metrics['f1']\n",
    "        current_best_ckpt_path = Path(args.ckpt_dir) / f\"best_exp{experiment_id}.pt\" # 실험 ID를 포함하여 저장\n",
    "        torch.save({\n",
    "            \"gcn\" : model.gcn.state_dict(),\n",
    "            \"proj\": model.proj_up.state_dict(),\n",
    "            \"lora\": model.glm.state_dict(),\n",
    "            \"optim\": optim.state_dict(),\n",
    "        }, current_best_ckpt_path)\n",
    "        print(f\"  ✔ 새로운 최적 체크포인트 저장됨 (F1 {best_f1:.4f} at {current_best_ckpt_path})\")\n",
    "\n",
    "# 최종 체크포인트 경로를 DB에 업데이트 (best.pt가 아닌 고유 경로)\n",
    "if current_best_ckpt_path:\n",
    "    # 이전에 best_f1 업데이트 시 checkpoint_path도 함께 업데이트 되도록 experiments.py 수정했으므로 중복될 수 있습니다.\n",
    "    # 필요하다면 여기서 한번 더 최종 업데이트를 강제할 수 있습니다.\n",
    "    pass # 이미 위에서 F1 업데이트 시 경로도 업데이트되므로 생략\n",
    "else:\n",
    "    print(\"최적 체크포인트가 저장되지 않았습니다.\")\n",
    "\n",
    "print(\"모델 훈련 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7018d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n테스트 세트 평가 시작...\")\n",
    "\n",
    "# 최적 체크포인트 경로가 없으면 에러 또는 기본값 사용\n",
    "if not current_best_ckpt_path or not current_best_ckpt_path.exists():\n",
    "    print(f\"[WARN] 최적 체크포인트 '{current_best_ckpt_path}'를 찾을 수 없습니다. 기본 체크포인트 사용 시도.\")\n",
    "    # 실제 환경에서는 여기서 오류 처리하거나 기본 ckpt 경로로 대체해야 합니다.\n",
    "    # 예시: current_best_ckpt_path = Path(args.ckpt_dir) / \"best.pt\"\n",
    "\n",
    "if current_best_ckpt_path and current_best_ckpt_path.exists():\n",
    "    # 모델 재로드 (최적 체크포인트 로드)\n",
    "    test_model = GraphTokenManager().half().to(device)\n",
    "    eval_load_ckpt(test_model, current_best_ckpt_path) # eval.py의 load_ckpt 함수 사용\n",
    "    print(f\"테스트 평가를 위해 모델에 '{current_best_ckpt_path}' 체크포인트 로드 완료.\")\n",
    "\n",
    "    # 테스트 데이터 로더 준비\n",
    "    test_loader = validate_get_loader( # validate.py의 get_loader 사용\n",
    "        db=args.db, cache=args.cache, frames=args.frames, wav=args.wav,\n",
    "        split=\"test\", max_samples=args.max_samples, seed=args.seed\n",
    "    )\n",
    "    print(f\"테스트 샘플: {len(test_loader.dataset)}\")\n",
    "\n",
    "    # 최종 평가 실행 (eval.py의 run_test 사용)\n",
    "    # run_test는 메트릭과 개별 예측 리스트를 반환합니다.\n",
    "    final_metrics, individual_predictions_list = eval_run_test(test_loader, test_model, device, Path(args.output_csv))\n",
    "    print(f\"\\n최종 테스트 메트릭: {json.dumps(final_metrics, indent=2)}\")\n",
    "\n",
    "    # DB에 최종 테스트 성능 업데이트\n",
    "    update_experiment_metrics(exp_conn, experiment_id, \"test\", final_metrics)\n",
    "    print(f\"실험 {experiment_id}의 최종 테스트 메트릭이 DB에 업데이트되었습니다.\")\n",
    "\n",
    "    # 개별 샘플 예측 결과 DB에 저장\n",
    "    insert_sample_predictions(exp_conn, experiment_id, individual_predictions_list, \"test\")\n",
    "    print(f\"{len(individual_predictions_list)}개의 개별 샘플 예측 결과가 DB에 저장되었습니다.\")\n",
    "\n",
    "    # 최종 메트릭 JSON 파일 저장\n",
    "    Path(args.output_json).write_text(json.dumps(final_metrics, indent=2))\n",
    "    print(f\"최종 결과가 {args.output_csv} 및 {args.output_json}에 저장되었습니다.\")\n",
    "\n",
    "else:\n",
    "    print(\"[ERROR] 테스트 평가를 위한 최적 체크포인트를 찾을 수 없습니다. 평가를 건너뜝니다.\")\n",
    "\n",
    "# 데이터베이스 연결 종료\n",
    "exp_conn.close()\n",
    "print(\"모든 실험 과정 완료 및 데이터베이스 연결 종료.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatglm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
