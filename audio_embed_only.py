#!/usr/bin/env python3
"""
audio_embed_only_v3.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Œ ëª©ì 
  1) ì„¸ê·¸ë¨¼íŠ¸ wav ì—†ìœ¼ë©´ ffmpeg ë¡œ ì¶”ì¶œ
  2) HuBERT-base ë¡œ 768-d ì˜¤ë””ì˜¤ ì„ë² ë”© ìƒì„±
  3) ë¬¼ë¦¬ GPU Ã— SLOTS_PER_GPU ê°œì˜ í”„ë¡œì„¸ìŠ¤ë¡œ ë™ì‹œ ì²˜ë¦¬
     (ì¹´ë“œë‹¹ HuBERT ìµœëŒ€ 3ê°œë§Œ ì˜¬ë¼ê°€ë„ë¡ ë©”ëª¨ë¦¬ ì œí•œ)

ì‹¤í–‰ ì˜ˆ
â”€â”€â”€â”€â”€â”€
# 0,1,2 ë²ˆ GPU ì„¸ ì¥ë§Œ ì‚¬ìš©
CUDA_VISIBLE_DEVICES=0,1,2,3 python audio_embed_only.py \
    --cache ./cache --workers 16
"""

from __future__ import annotations
import os, sqlite3, subprocess, argparse, multiprocessing as mp
from pathlib import Path
from typing import Dict, List, Tuple
from concurrent.futures import ProcessPoolExecutor, as_completed

import torch
from tqdm import tqdm

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²½ë¡œ ë° í•˜ë“œì½”ë”© ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DB_PATH   = "data/speech_segments.db"
RAW_VDIR  = Path("/mnt/shares/videos")
WAV_ROOT  = Path("/mnt/third_ssd/data/wav")
CACHE_DIR = Path("./cache")

SLOTS_PER_GPU   =  5           # ì¹´ë“œë‹¹ HuBERT ì¸ìŠ¤í„´ìŠ¤ ìˆ˜
THREADS_PER_PROC = 4           # í•œ í”„ë¡œì„¸ìŠ¤ë‹¹ CPU ì‘ì—… ìŠ¤ë ˆë“œ ìˆ˜
FPS              = 1           # í”„ë ˆì„ ì¶”ì¶œ fps (wav ìƒì„±ë§Œ í•  ë•ŒëŠ” ì‚¬ìš© ì•ˆ í•¨)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Helper: ffmpeg ë¡œ wav ì¶”ì¶œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def ensure_wav(video_id: str, seg_id: str, st: float, et: float) -> Path:
    vid_file = RAW_VDIR / f"{video_id}.mp4"
    wav_path = WAV_ROOT / video_id / f"{seg_id}.wav"
    if wav_path.exists():
        return wav_path

    wav_path.parent.mkdir(parents=True, exist_ok=True)
    cmd = [
        "ffmpeg", "-nostdin", "-loglevel", "error", "-y",
        "-ss", str(st), "-to", str(et), "-i", str(vid_file),
        "-ar", "16000", "-ac", "1", str(wav_path)
    ]
    subprocess.run(cmd, check=True)
    return wav_path


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# embed_utils_audio ì „ìš© í•¨ìˆ˜ â€“ GPU í”„ë¡œì„¸ìŠ¤ì—ì„œë§Œ import
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def embed_audio_only(wav_path: Path, cache_dir: Path, seg_id: str):
    from embed_utils_audio import embed_audio_only  # <- ê²½ëŸ‰ ëª¨ë“ˆ
    embed_audio_only(wav_path, cache_dir, seg_id)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë¹„ë””ì˜¤ë³„ ì˜¤ë””ì˜¤ ì„ë² ë”© ì§„í–‰ë¥  ê³„ì‚°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def audio_ready_ratio(seg_ids: List[str],
                      cache_dir: Path) -> float:
    total = len(seg_ids)
    have  = sum(
        (cache_dir / f"{seg_id}.pt").exists()
        for seg_id in seg_ids
    )
    return have / total if total else 0.0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GPU ìŠ¬ë¡¯ë³„ ì›Œì»¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def slot_worker(gpu_id: int,
                slot_idx: int,
                videos: List[str],
                seg_rows: Dict[str, List[Tuple]],
                cpu_threads: int,
                cache_dir: Path):

    os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
    desc = f"GPU{gpu_id}-S{slot_idx}"
    fails = 0

    with ProcessPoolExecutor(max_workers=cpu_threads) as ex:
        for vid in videos:
            rows = seg_rows[vid]
            futs = []

            for seg_id, st, et in rows:
                wav_path = ensure_wav(vid, seg_id, st, et)
                futs.append(
                    ex.submit(embed_audio_only, wav_path, cache_dir, seg_id)
                )

            pbar = tqdm(as_completed(futs),
                         total=len(futs),
                         ncols=90,
                         desc=f"{desc} {vid[:10]}")
            for fut in pbar:
                try:
                    fut.result()
                except Exception as e:
                    fails += 1
                    pbar.write(f"âš  {e}")

    print(f"[{desc}] done. fails={fails}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë©”ì¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--cache",   default=str(CACHE_DIR))
    ap.add_argument("--workers", type=int, default=os.cpu_count())
    args = ap.parse_args()

    cache_dir = Path(args.cache)
    cache_dir.mkdir(exist_ok=True)

    # â”€â”€ DB ë¡œë“œ: video_id â†’ [(seg_id, st, et)â€¦] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    conn = sqlite3.connect(DB_PATH); conn.row_factory = sqlite3.Row
    cur = conn.execute(
        "SELECT video_id, segment_id, start_time, end_time "
        "FROM speech_segments"
    )
    video2rows: Dict[str, List[Tuple[str, float, float]]] = {}
    for r in cur.fetchall():
        video2rows.setdefault(r["video_id"], []).append(
            (r["segment_id"], r["start_time"], r["end_time"]))
    conn.close()

    # â”€â”€ ì§„ì²™ë¥  ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    sorted_videos = sorted(video2rows.keys(),
                           key=lambda v: audio_ready_ratio(
                               [s[0] for s in video2rows[v]], cache_dir),
                           reverse=True)

    # â”€â”€ ìŠ¬ë¡¯ ë¶„ë°° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    total_slots = torch.cuda.device_count() * SLOTS_PER_GPU
    shards = [sorted_videos[i::total_slots] for i in range(total_slots)]

    print(f"Total videos: {len(sorted_videos)} ; GPUs: "
          f"{torch.cuda.device_count()} ; Slots: {total_slots}")

    cpu_per_proc = max(1, args.workers // total_slots)
    procs = []
    slot_id = 0
    for gpu in range(torch.cuda.device_count()):
        for local in range(SLOTS_PER_GPU):
            vids = shards[slot_id]
            p = mp.Process(target=slot_worker,
                           args=(gpu, local, vids,
                                 video2rows, cpu_per_proc, cache_dir))
            p.start(); procs.append(p)
            print(f"Spawned GPU{gpu}-S{local} : {len(vids)} videos "
                  f"(CPU {cpu_per_proc})")
            slot_id += 1

    for p in procs: p.join()
    print("âœ… All slots finished.")


if __name__ == "__main__":
    mp.set_start_method("spawn", force=True)
    main()
